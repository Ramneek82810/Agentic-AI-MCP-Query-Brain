# ğŸ§  Agentic-AI-MCP-Query-Brain

An intelligent, agentic system built with **Model Context Protocol (MCP)** that transforms natural language queries into SQL, executes them against a database, and returns human-friendly results. Powered by modular microservices, Redis memory, and PostgreSQL for robust, context-aware querying.

---

## ğŸ“Œ Overview

This project enables you to ask questions in plain English and receive structured data answers. It does so using:

- A **modular MCP architecture** for agent-to-tool communication  
- **FastAPI microservices** hosting API endpoints  
- **Redis memory** for storing conversational context  
- **OpenAI / LLM integration** for generating SQL  
- **PostgreSQL backend** for executing queries  
- **Docker + NGINX** setup for production scalability  

---

## ğŸ§  Tech Stack

| Component             | Technology                          |
|-----------------------|--------------------------------------|
| Language              | Python 3.12                          |
| Web Framework         | FastAPI                              |
| AI / LLM Integration  | OpenAI (via LLM)                     |
| Memory Store          | Redis                                |
| Database              | PostgreSQL                           |
| Containerization      | Docker & Docker Compose              |
| Reverse Proxy / Load Balancer | NGINX                      |
| Communication         | JSON over standard I/O / HTTP        |

---

## ğŸ“ Project Structure

```
Agentic-AI-MCP-Query-Brain/
â”œâ”€â”€ agent/                     # Core MCP agent logic
â”œâ”€â”€ api_client/                # Client side communication logic
â”œâ”€â”€ api_service/               # FastAPI based endpoints
â”œâ”€â”€ docker/                    # Dockerfiles & container setup
â”œâ”€â”€ memory/                    # Redis memory and context logic
â”œâ”€â”€ models/                    # Data models & schema definitions
â”œâ”€â”€ sdk/                       # MCP SDK & router utilities
â”œâ”€â”€ services/                  # Tool registry and helper services
â”œâ”€â”€ sql_tool/                  # SQL execution, explanation & validation
â”‚
â”œâ”€â”€ main.py                     # FastAPI entry point
â”œâ”€â”€ main_stdio.py               # MCP host via stdio runner
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ docker-compose.yml          # Multi-container orchestration
â”œâ”€â”€ nginx.conf                   # NGINX configuration
â””â”€â”€ README.md                    # This documentation
```

---

## ğŸ§© Key Tools & Modules

- **OpenAITool** â€” Converts natural language queries to SQL  
- **SQLTool** â€” Executes SQL on PostgreSQL securely  
- **ExplainSQLTool** â€” Converts SQL into readable descriptions  
- **QueryCacheTool** â€” Caches commonly run queries  
- **FeedbackLoggingTool** â€” Logs user feedback for model tuning  
- **NaturalLanguageResponseTool** â€” Turns SQL results into textual responses  
- **RateLimiterTool** â€” Controls request throughput  
- **TableSchemaTool** â€” Retrieves schema metadata for better query accuracy  

---

## ğŸ§  How It Works

1. **User input** (natural language) is sent via the frontend or CLI.  
2. The **MCP Host** routes the input to the appropriate tool.  
3. **OpenAITool** generates SQL from the input using LLM reasoning.  
4. **SQLTool** executes the query on PostgreSQL, returning raw results.  
5. **NaturalLanguageResponseTool** translates results into readable form.  
6. **Redis memory** retains conversation context for follow-up queries.

---

## âš™ï¸ Example Configuration Snippet (VS Code / MCP)

Use this example in your MCP setup (sensitive keys masked for security):

```json
{
  "mcpServers": {
    "vartopia-sql-agent": {
      "command": "D:/vartopia/.venv/Scripts/python.exe",
      "args": [
        "-u",
        "D:/vartopia/main_stdio.py"
      ],
      "env": {
        "OPENAI_API_KEY": "sk-proj-********-REDACTED",
        "DB_URL": "postgresql://mcp_postgres_user:********@render.com/mcp_postgres",
        "REDIS_URL": "redis://localhost:6379"
      },
      "transport": "stdio",
      "workingDirectory": "D:/vartopia"
    }
  }
}
```

---

## â–¶ï¸ Getting Started

### âœ… Prerequisites

- Python 3.12+  
- PostgreSQL database  
- Redis server  
- Docker & Docker Compose (optional, but recommended)

### ğŸ›  Setup Steps

1. **Clone the repository**
   ```bash
   git clone https://github.com/Ramneek82810/Agentic-AI-MCP-Query-Brain.git
   cd Agentic-AI-MCP-Query-Brain
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the FastAPI service**
   ```bash
   uvicorn main:app --reload
   ```

4. **Or start with Docker (multi-container setup)**
   ```bash
   docker-compose up --build
   ```

---

## ğŸ§  Architecture Flow

```
User Input
   â†“
MCP Client â†’ MCP Host (FastAPI)
   â†“
Tool Router â†’ [OpenAITool â‡„ SQLTool â‡„ MemoryTool]
   â†“
Redis Memory â†” PostgreSQL
   â†“
Formatted JSON or Natural Language Response
```

---

## ğŸ§© Example Use Case

**Input:**  
> â€œShow the top 5 sales by department for the last quarter.â€

**Pipeline:**  
- OpenAITool â†’ Generates SQL  
- SQLTool â†’ Executes query  
- NaturalLanguageResponseTool â†’ Formats the results  

**Output:**  
> â€œHere are the top 5 departments by sales last quarter: Electronics, Home, Fashion, Sports, and Toys.â€

---

## ğŸ“ˆ Future Enhancements

- ğŸ—„ Multi-database support (MySQL, MongoDB)  
- ğŸ§  Custom fine-tuned LLMs for SQL generation  
- ğŸ›¡ Role-based authentication & access control  
- ğŸ¤– Multi-agent orchestration for complex workflows  

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” free to use, modify, and distribute with attribution.

